{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aV1PgZf3oucJ"
      },
      "source": [
        "# Data sense making\n",
        "\n",
        " 1. Case study: the most studied artistic and historical periods\n",
        " \n",
        " 2. Case study: the most studied artistic and historical periods over time\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Usually, the first step should be to understand the added value of a given dataset, which requires the exploration to be performed **over the whole dataset**. \n",
        "\n",
        "For the sake of this tutorial, we start from: \n",
        "\n",
        " * a given research question \n",
        " * a subset of the ARTchives graph. \n",
        " \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Case study: the most studied artistic and historical periods\n",
        "\n",
        "We want to answer the following question:\n",
        "\n",
        "```\n",
        "What are the most studied artistic and historical periods according to ARTchives?\n",
        "```\n",
        "\n",
        "This question implies us to get some **statistics**, i.e. the distribution of artistic periods that are subjects of archival collections. This is the simplest **univariate analysis** possible on a dataset. \n",
        "\n",
        " * We consider a *categorial attribute* (the artistic period) \n",
        " * we look for the *numerical* distribution of the categorical attribute in the dataset (counting). \n",
        " \n",
        "In order to answer this question we need to go through the seven stages of information visualization, namely:\n",
        "\n",
        " * acquire\n",
        " * parse\n",
        " * filter\n",
        " * mine\n",
        " * represent\n",
        " * refine\n",
        " * interact \n",
        "\n",
        "\n",
        "### 1.1. Acquire and parse\n",
        "\n",
        "We leverage the RDF dump of ARTchives data (`../resources/artchives.nq`). We parse the data by using the RDFLib python library."
      ],
      "metadata": {
        "id": "fbQZwk4jo71x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0arCbGmWoucN"
      },
      "outputs": [],
      "source": [
        "# uncomment if colab\n",
        "#!pip install rdflib\n",
        "import rdflib\n",
        "from rdflib import Namespace , Literal , URIRef\n",
        "from rdflib.namespace import RDF , RDFS\n",
        "\n",
        "# bind the uncommon namespaces\n",
        "wd = Namespace(\"http://www.wikidata.org/entity/\") # remember that a prefix matches a URI until the last slash (or hashtag #)\n",
        "wdt = Namespace(\"http://www.wikidata.org/prop/direct/\")\n",
        "art = Namespace(\"https://w3id.org/artchives/\")\n",
        "\n",
        "# create an empty Graph\n",
        "g = rdflib.ConjunctiveGraph()\n",
        "\n",
        "# parse a local RDF file by specifying the format\n",
        "result = g.parse(\"https://raw.githubusercontent.com/marilenadaquino/information_visualization/main/2022-2023/resources/artchives.nq\", format='nquads')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oALaAxUroucO"
      },
      "source": [
        "#### 1.1.2  Filtering\n",
        "\n",
        "In order to answer our research question we need to work only on a **subset of the graph**.\n",
        "\n",
        " * archival collections (individuals of the class `wd:Q9388534`)\n",
        " * subjects of the collections (`wd:Q9388534 > wdt:P921 > ?period`)\n",
        " * among the subjects, we have artistic and historical periods. Subject periods are also the range of the property `art:hasSubjectPeriod`. \n",
        "\n",
        "We need to extract **for each artistic period**: \n",
        " \n",
        " * only one name associated to the artistic period (values of the property `art:hasSubjectPeriod / rdfs:label`)\n",
        " * all the collections linked to the artistic period (the domain of the property `art:hasSubjectPeriod`)\n",
        " * the counting of collections linked to the artistic period (either in SPARQL via `(COUNT(?collections) AS ?count)` or in python)\n",
        "\n",
        "Step by step:\n",
        "\n",
        " * We query the graph, looking for periods and collections. Rather than iterating over triples, we use a sparql query. \n",
        " * We ask for collections `?coll`, their labels `?coll_label`, their associated artistic period `?period`, and their label `?period_label`. \n",
        " * We want only one label for each term (collection or period), hence we use `SAMPLE` to return 1 label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LVjJ1V1foucP"
      },
      "outputs": [],
      "source": [
        "# query the graph\n",
        "query_periods = g.query(\n",
        "    \"\"\"SELECT (SAMPLE(?coll_label) AS ?coll) (SAMPLE(?label) AS ?period_label) # we want only one label!\n",
        "    WHERE {\n",
        "        ?coll <https://w3id.org/artchives/hasSubjectPeriod> ?period ; \n",
        "              rdfs:label ?coll_label .\n",
        "        ?period rdfs:label ?label .\n",
        "    }\n",
        "    GROUP BY ?period ?coll\n",
        "    ORDER BY ?period_label\"\"\") \n",
        "\n",
        "# try the query on http://artchives.fondazionezeri.unibo.it/sparql to see the results!\n",
        "for coll, period in query_periods:\n",
        "  print(period.strip(), \" - \", coll)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Suhd6ZeoucP"
      },
      "source": [
        "### 1.2 Mine data\n",
        "\n",
        "In order to use some popular python library for data mining and visualization we must transform data in **tabular form**. \n",
        "We prepare a table (a .csv file) with two columns (`collection`, `period_label`) and we store results of the query there.\n",
        "\n",
        "In our case, we want to plot the distribution of periods in a **bar chart**. Therefore we filter graph to get data about collections and subject periods, and we create a table wherein each row includes (1) a collection and (2) an artistic period."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "KKasDAG7oucQ"
      },
      "outputs": [],
      "source": [
        "# import csv built-in library\n",
        "import csv\n",
        "\n",
        "# prepare the csv file\n",
        "with open('periods_count.csv', mode='w') as my_file:\n",
        "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
        "    # write the column names\n",
        "    my_writer.writerow(['collection', 'period_label'])\n",
        "    \n",
        "    # access the list of tuples of the query results\n",
        "    for res in query_periods:\n",
        "        # write in the csv\n",
        "        my_writer.writerow([res['coll'], res['period_label'].strip()])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yFoHk6ZGoucR"
      },
      "source": [
        "\n",
        "\n",
        "We introduce now **Pandas**, a Python library for **data analysis**. \n",
        "\n",
        "Pandas requires us to parse data (from csv or json) in a new data structure called data frame (similar to a table) so that we can use some useful methods for the analysis and visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MlziPP_KoucR"
      },
      "outputs": [],
      "source": [
        "# pandas\n",
        "import pandas as pd\n",
        "\n",
        "# parse the csv into a dataframe\n",
        "df = pd.read_csv(\"periods_count.csv\")\n",
        "# print the first 15 rows\n",
        "df.head(15)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEdF48i8oucS"
      },
      "source": [
        "### 1.3 Represent: Profiling and exploration, plotting data\n",
        "\n",
        "A useful library is **pandas_profiling** that generates reports from a pandas dataframe, including basic statistics on the datasets and a few exploratory visualizations. This is very useful when you are working on big tables with many columns and rows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lQwwvEnoucS"
      },
      "outputs": [],
      "source": [
        "# uncomment and restart the kernel if colab\n",
        "#! pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip \n",
        "import pandas_profiling as pp\n",
        "pp.ProfileReport(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c51ik_R2oucT"
      },
      "source": [
        "To plot our data with Python in Jupyter we have plenty of libraries that support us. In this tutorial we use **seaborn**, a library for plotting data organised in data frames. See the [online documentation](https://seaborn.pydata.org/) with plenty of tutorials."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q_qPYX9MoucT"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Apply the default theme\n",
        "# sns.set_theme() in older versions of seaborn\n",
        "sns.set()\n",
        "\n",
        "# rename data frame\n",
        "periods = df\n",
        "\n",
        "# count function to show the number of observations of a category (period_label) in a dataset as a bar chart\n",
        "# see documentation here https://seaborn.pydata.org/generated/seaborn.catplot.html\n",
        "my_plot = sns.catplot(y=\"period_label\", kind=\"count\", data=periods)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uz9aT7EYoucT"
      },
      "source": [
        "The library allows us to save plots as images - possibly, to be included in a web page :)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Onu940ueoucU"
      },
      "outputs": [],
      "source": [
        "my_plot.savefig(\"distribution.png\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NWe3c2h1oucU"
      },
      "source": [
        "## 2 Case study: what are the most studied artistic and historical periods studied over time\n",
        "\n",
        "We want to answer the following question:\n",
        "\n",
        "```\n",
        "What are the most studied artistic and historical periods studied over time according to ARTchives?\n",
        "```\n",
        "\n",
        "This question implies us to get some **temporal** insights, when and to what extent collections reference a certain artistic period.\n",
        " \n",
        "In order to answer this question we need to go through the seven stages of information visualization, namely:\n",
        "\n",
        " * acquire\n",
        " * parse\n",
        " * filter\n",
        " * mine\n",
        " * represent\n",
        " * refine\n",
        " * interact \n",
        " \n",
        " \n",
        "### 2.1. Acquire, parse, and filter data\n",
        "\n",
        " * We leverage the same RDF dump of ARTchives data (`../resources/artchives.nq`). \n",
        " * We parse the data by using the RDFLib python library.\n",
        "\n",
        "\n",
        "### 2.2 Filtering\n",
        "In order to answer our research question we need to work only on a subset of the graph.\n",
        "\n",
        " * archival collections are annotated with the timespan of the creator's activity (earliest date `wd:Q9388534 > wdt:P1319 > ?earliest` and latest date `wd:Q9388534 > wdt:P1326 > ?latest`)\n",
        "\n",
        "For the **temporal analysis**, we need to extract:  \n",
        "\n",
        " * the names of the artistic periods (values of the property `art:hasSubjectPeriod / rdfs:label`)\n",
        " * the timespans of collections (earliest `wdt:P1319` and latest `wdt:P1326`)\n",
        "\n",
        "This is a *bivariate* analysis, looking for the distribution of a *categorial attribute* over time. The aim is to find an association between time spans and topics (artistic periods) in the dataset.\n",
        "\n",
        "**AND NOW?** To make the analysis easier, we extract the data we need in **separate data structures** from the original one. \n",
        "\n",
        "In order to use some popular python library for plotting data in Jupyter, we must have (again) data in **tabular form**. We want to plot our data in a **line graph**, where it's easier to see trends. \n",
        "\n",
        "Step by step:\n",
        "\n",
        " * We query our the graph, looking for subject periods, collections, collections dates. \n",
        " * Rather than iterating over triples, we use a sparql query. \n",
        " * We need to take into account that some collections may not have some variables. The results of our query will include in every row a unique combination of periods, collections, and collections dates if available"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HzmGOmvGoucU"
      },
      "outputs": [],
      "source": [
        "# sparql\n",
        "\n",
        "query_periods_dates = g.query(\n",
        "    \"\"\"PREFIX wdt: <http://www.wikidata.org/prop/direct/>\n",
        "    SELECT (SAMPLE(?coll_label) AS ?coll) (SAMPLE(?label) AS ?period_label) ?earliest ?latest\n",
        "    WHERE {?coll <https://w3id.org/artchives/hasSubjectPeriod> ?period ; rdfs:label ?coll_label .\n",
        "    ?period rdfs:label ?label .\n",
        "    OPTIONAL {?coll wdt:P1319 ?earliest}\n",
        "    OPTIONAL {?coll wdt:P1326 ?latest}\n",
        "    }\n",
        "    GROUP BY ?period ?coll ?earliest ?latest\n",
        "    ORDER BY ?period_label\"\"\") "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4UPtCj2oucV"
      },
      "source": [
        "### 2.2. Mine data\n",
        "\n",
        "In order to plot periods distribution over time, we need a **time series**, meaning a **continuous** series of time observations (in our case we simplify observations to years). However, we have only time ranges (e.g. 1910-1986). We need to **expand the results** of the query with intermediate points.\n",
        "\n",
        " * We iterate over the results of the query (a list of tuples) and for each result (coll, period, earliest, latest) we create a new tuple (coll, period, year) where the year is a number included in the range(earliest,latest)\n",
        " * We create a python list to store the new tuples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pO_kI9CgoucV"
      },
      "outputs": [],
      "source": [
        "# the new list\n",
        "periods_dates_expanded = []\n",
        "\n",
        "# query the list of tuples of query results\n",
        "for res in query_periods_dates:\n",
        "    # pruning results without dates (NB. I know all collections have dates) \n",
        "    if res[\"earliest\"] is not None and res[\"latest\"] is not None:\n",
        "        timespan = list(range( int(res[\"earliest\"][:4]), int(res[\"latest\"][:4])+1 ))\n",
        "        for year in timespan:\n",
        "            periods_dates_expanded.append( ( str(res[\"coll\"]).strip(), str(res[\"period_label\"]).strip(), str(year)) ) # append a tuple!\n",
        "            \n",
        "print(periods_dates_expanded)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4_vWLp2oucV"
      },
      "source": [
        "* We prepare a table (a .csv file) with three columns (`collection`, `period_label`, `year`) and we write our results of the query there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "GeHfgPuZoucV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# prepare the csv file\n",
        "with open('periods_dates.csv', mode='w') as my_file:\n",
        "    my_writer = csv.writer(my_file, delimiter=',', quotechar='\"', quoting=csv.QUOTE_ALL)\n",
        "    # write the column names\n",
        "    my_writer.writerow(['collection', 'period_label', 'year'])\n",
        "    \n",
        "    # access the rows of the query results\n",
        "    for coll, label, year in periods_dates_expanded:\n",
        "        # write in the csv\n",
        "        my_writer.writerow([coll.strip(), label.strip(), year])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvWyc8CXoucV"
      },
      "source": [
        " * We parse the table in a data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O8o7dSuwoucW"
      },
      "outputs": [],
      "source": [
        "# parse the csv into a dataframe\n",
        "data = pd.read_csv(\"periods_dates.csv\")\n",
        "# print the first 5 rows\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aKeU1n74oucW"
      },
      "source": [
        "In order to visualize the artistic periods through the time series (x axis), and the number of collections linked to the period (y axis), we need to re-organize the dataframe. \n",
        "\n",
        " * we do not need the collection names\n",
        " * we need pairs period/year\n",
        " * for each pair period/year we need the number of collections in which the period appears\n",
        "\n",
        "Pandas allows us to create new dataframes from an existing one **by grouping rows** according to values included in one or more columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8HgLcfSoucW"
      },
      "outputs": [],
      "source": [
        "# group rows by period and year, hence add a column with the counting of collections\n",
        "data_by_year = data.groupby( [\"period_label\", \"year\"] ).size().reset_index()\n",
        "# rename the columns\n",
        "data_by_year.columns = [\"period_label\", \"year\", \"count_coll\"]\n",
        "# see the first rows\n",
        "data_by_year.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f0MtsCqboucW"
      },
      "source": [
        "### 1.3 Represent: Profiling and exploration, plotting data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "yH5amr0aoucW"
      },
      "outputs": [],
      "source": [
        "# profiling\n",
        "pp.ProfileReport(data_by_year)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a2LN8XVooucX"
      },
      "source": [
        "To make the initial exploration easier, we can create as many charts as the periods, by using **relplot** in seaborn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbeVzjOzoucX"
      },
      "outputs": [],
      "source": [
        "# plotting\n",
        "# see documentation here https://seaborn.pydata.org/generated/seaborn.relplot.html\n",
        "mult_plot = sns.relplot(x=\"year\", y=\"count_coll\", hue=\"period_label\", \n",
        "            col=\"period_label\", col_wrap=3,\n",
        "            height=4, aspect=1.75, linewidth=2.5,\n",
        "            kind=\"line\", data=data_by_year);\n",
        "\n",
        "# reset the x origin to year 1870\n",
        "mult_plot.set(xlim=(1870, 2020)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvEX75bmoucX"
      },
      "source": [
        "We can now compare all the periods in the same plot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BtRfEALUoucX"
      },
      "outputs": [],
      "source": [
        "my_pl = sns.relplot(x=\"year\", y=\"count_coll\", hue=\"period_label\",\n",
        "            height=5, aspect=1.75, linewidth=1,\n",
        "            kind=\"line\", data=data_by_year);\n",
        "\n",
        "# reset the x origin to year 1870\n",
        "my_pl.set(xlim=(1870, 2021))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LjmhXgYfoucX"
      },
      "source": [
        "## In summary. How to plan your work\n",
        "\n",
        " * choose a research question\n",
        " * define pieces of information needed to answer the question (e.g. *What are the most studied artistic and historical periods according to ARTchives?* requires artistic periods and their counting)\n",
        " * map pieces of information to their data types (i.e. categorical, numerical)\n",
        " * choose the plot according to the data types you have and the patter you want to visualize (e.g. a bar chart to compare quantities and highlight the highest)\n",
        " * get your data (e.g. download, \n",
        " * perform a a SPARQL query to filter/ manipulate your data (select the variables that matter, make operations like countings) \n",
        " * study requirements of your data visualization library \n",
        "   * what is the input data format? usually a table\n",
        "   * what is the expected organisation? e.g.every row should include an artistic period and its counting\n",
        "   * what data types are accepted? e.g. strings and integers\n",
        " * create a data structure that fits the plotting requirements\n",
        " * plot the result in your IDE\n",
        " * tweak the chart (add titles, labels, change colors, etc.)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RWeCAA-loucX"
      },
      "source": [
        "## Exercise: Represent and refine\n",
        "\n",
        " * Visualise the distribution of periods in the dataset (case study 1) as a dot chart (look at this [tutorial](https://seaborn.pydata.org/tutorial/categorical.html#categorical-scatterplots).).\n",
        " * set the size of the plot (see this [tutorial](https://www.datacamp.com/community/tutorials/seaborn-python-tutorial?utm_source=adwords_ppc&utm_campaignid=898687156&utm_adgroupid=48947256715&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=332602034349&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=20616&gclid=Cj0KCQiAwMP9BRCzARIsAPWTJ_ETdq6AK5GBlFVxsKC9csqzAJsaOY7LirXfWLZ40ITxrglJLCQxT_oaAny_EALw_wcB#figsize))\n",
        " * rotate labels on the x axis (see this [tutorial](https://www.datacamp.com/community/tutorials/seaborn-python-tutorial?utm_source=adwords_ppc&utm_campaignid=898687156&utm_adgroupid=48947256715&utm_device=c&utm_keyword=&utm_matchtype=b&utm_network=g&utm_adpostion=&utm_creative=332602034349&utm_targetid=dsa-429603003980&utm_loc_interest_ms=&utm_loc_physical_ms=20616&gclid=Cj0KCQiAwMP9BRCzARIsAPWTJ_ETdq6AK5GBlFVxsKC9csqzAJsaOY7LirXfWLZ40ITxrglJLCQxT_oaAny_EALw_wcB#rotate))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2OVDSHZboucX"
      },
      "outputs": [],
      "source": [
        "# solution"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "colab": {
      "name": "dataviz_tutorial.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}